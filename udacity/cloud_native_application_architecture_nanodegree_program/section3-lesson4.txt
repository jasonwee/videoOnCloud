date start : 30 august 2021


4.1 Lesson Overview
---------------------------------------
Implementing Message Passing

So far in our course, we have learned:

How and when it makes sense to take apart a monolith application into microservices
Different forms of message passing with REST, gRPC, and message queues.

In this lesson, we will be working on applying and implementing message passing techniques. We will learn about how to set up servers and clients for:

REST
gRPC
Kafka

Programming Language: Python
We will use common libraries and tools to implement these technologies.

Once you have a core understanding of how to implement a message passing technique with Python libraries, you should be able to use these technologies in other contexts.

By the end of this lesson you will be able to:

Use REST to implement a RESTful API and consumer
Use gRPC to implement a gRPC server and client
Use Kafka to implement a distributed message queue



4.2 Why Does Implementing Message Passing Matter?
---------------------------------------
Why Does Implementing Message Passing Matter?

By implementing well thought-out designs, we can save money in infrastructure costs or we can enable our services to run with minimal downtime to prevent loss of business.

Business Importance
Message passing today is integral to an industry where businesses can leverage integrations from Software as a Service providers.

Some businesses have thrived partly due to their well-crafted APIs. Their well-crafted APIs and supporting documentation can be a defining factor for adoption.

Freemium Models
Today, it is common for businesses to offer a freemium model: hobbyists can sign up and use a free service within some usage limits.

Once the users have a good experience using the tools and integrations, it is common for them to gravitate towards using them in their professional roles.
An API that is unreliable and has a poor user experience would be a great hindrance to the adoption of the business' tools and services.

Technological Importance
It's important to make decisions on technologies that will satisfy today's business requirements as well as provide a roadmap for future iterations.
We need to understand the inspirations for certain message passing techniques and how they can be improved if business requirements change.
It's not a good idea to blindly apply trendy technologies without understanding the impact that it will have.
Throughout your career, new trends will come and go with different technologies that one can use in their systems.
You should be able to weigh the tradeoffs of these tools and build maintainable systems that will have a great business impact.

q1
Create and maintain documentation for developers to understand how to use and implement the API
Ensure that new changes to the API won't break existing code implemented by users
Set up a reliable infrastructure to reduce the downtime that services experience



4.3 Who is Our User?
---------------------------------------
Internal versus External Usage
It is often useful to consider whether it is used internally or externally.

Internal refers to applications inside a microservice or other projects that you or your team own.
External refers to other teams in an organization or customers outside of the organization.

The key concepts are:
You typically have more control over internal applications and can be relatively reactive and iterative quickly on changes.
We should be aware of who will be using our APIs, and we should tailor our message passing techniques to optimize for their usability and business needs.

Internal vs External
It is a little easier to be more open-ended and ambitious with your message passing implementations in internal systems.

External applications should be a bit safer and abide by what is dominant in the industry.
gRPC
gRPC is becoming very popular but is still not as widely adopted in the industry.
You will likely encounter developers who have never worked with or have even heard of gRPC.
gRPC may be a great way to optimize internal services since knowledge transfer within a team is more fluid and requires less buy-in from stakeholders.
REST
REST is very popular, and it is a term that's well-recognized by sales engineers.
If you are building an external system, REST may be the ideal approach to achieve widespread adoption.

q1
We can more easily track down where our applications are used by referencing the logs and code repositories in our organization.
We can often connect directly with the stakeholders and coordinate on the changes.
Users in the same organization can share more empathy and understand the business decisions that drive necessary but breaking changes.



4.4 Using REST
---------------------------------------
Technologies
We will build a RESTful API server with a micro-framework called Flask, and a client called requests. These two tools are used very commonly in the industry.

Flask - REST API Server
A framework helps you write programs more productively by providing you some tools and utilities. Different frameworks have various degrees of how imposing they are in making you write programs that conform to their style. Flask is known as a micro framework and tries to remain more open-ended in letting you decide how to organize and write your code.

Read the official documentation for Flask.
https://flask.palletsprojects.com/en/1.1.x/


Simple Flask App

GET Requests
With Flask, we can define API routes and how they are handled. For example, a GET request for an API can be defined as follows:

@app.route('/test`, methods=['GET'])
def test():
    result = "Hello, world!"
    return result
Base Case Flask Application Example
We can make this request more RESTful by importing the json library to manage JSON responses.

import json
from flask import Flask, Response

app = Flask(__name__)

@app.route('/health', methods=['GET'])
def health():
    result = json.dumps({'result': 'Hello, World!'})
    header = {'Content-Type': 'application/json'}
    status_code = 200
    return Response(result, status_code, header)

Simplified REST API
The following is a simple Flask REST API application using built-in tooling to reduce boilerplate code:

from flask import Flask, jsonify

app = Flask(__name__)

@app.route('/health', methods=['GET'])
def health():
    result = {'result': 'Hello, World!'}
    return jsonify(result)
app.route('/health', methods=['GET']) defines that we are exposing an API endpoint atGET /health
def health() is the method that is invoked when the API is called
jsonify(result) reduces the boilerplate to turn our Python dictionary into a JSON response with a response code

Flask and the Requests Library

Requests - REST API Client
Requests is a popular library that makes it easy to make HTTP requests. It makes things easier by providing a straightforward interface to set up your requests and process responses. For more details, see the Requests Quickstart guide.

Request Library Syntax
# GET Request
get_result = requests.get(API_URL)

# PUT Request
put_result = requests.put(API_URL, data={'key': 'value'})

# POST Request
post_result = requests.post(API_URL, data={'key': 'value'})

# DELETE Request
delete_result = requests.delete(API_URL)

Simple Requests Application Example
The following is a simple Requests application:

import requests

r = requests.get(ENDPOINT_URL)
if r.status_code == 200:
    print(r.json())

requests.get(ENDPOINT_URL) makes a GET request to the defined URL
r.status_code provides us the HTTP response code
r.json() provides us an easy way to retrieve the data as a JSON object

Building A REST Endpoint with Flask
Follow Along
You can follow along with the demo by using the code here: Flask REST Demo

Summary
1. Install Flask
Flask can be installed with the Python package manager, pip: pip install Flask
Validate that it was installed with pip list
2. Create REST Application
Create a file named app.py for the API server
Import Flask in the code to make it available
Set up the Flask application with app = Flask(__name__)
Create a method named health() that will return a JSON response using jsonify() to format a dictionary
Add the app.route decorator on the health() method to configure how the code will handle an API request to/health
3. Run REST Application
flask run in the same directory as app.py will start the application on localhost:5000
4. Install Requests
Requests can be installed with the Python package manager, pip: pip install requests
Validate that it was installed with pip list
5. Create REST Client
Create a file named client.py for the API client
Import Requests in the cdoe to make it available
Make a GET request to localhost:5000/health and print the result
6. Make a REST API Request
Run client.py to make an API request to the Flask API server

New Terms
Term	Definition
Flask	A popular Python framework often used to build APIs
Requests	A popular Python HTTP library
Learn More About Frameworks for REST
Below are some additional libraries and frameworks used for creating HTTP server and HTTP clients:

FastAPI - Newer Python framework for creating APIs
Django - A very popular Python framework for creating APIs
urllib3 - Low-level library for Python HTTP requests



4.5 Using Postman to Test APIs
---------------------------------------
Getting Started With Postman
Postman provides useful tools to make HTTP requests and view the data in the HTTP responses. It can also be used for:

Organizing and sharing HTTP requests as collections
API documentation
To get started with Postman, go to: Download Postman.

New Terms
Term	Definition
Postman	An application that provides useful tools for testing APIs



4.6 Quizzes: Using REST
---------------------------------------
Postman provides tools to organize API requests.
Postman is programming-language agnostic



4.7 Exercise: Using REST
---------------------------------------
Implementing a REST API
For this exercise, we will be implementing the REST API that you have designed in the previous lesson for placing computer orders. We will be using the boilerplate code provided here to get you started: Using REST Starter.

Since we want to focus on building out the API definitions, feel free to stub out the code's actual logic similar to the boilerplate code. We can assume the computer service returns a hard-coded value. You should focus on understanding the basic Flask features in creating an API and understanding how our definitions translate into code.

References
Flask Demo
You may find it useful to reference the demo code: Flask Demo Application

API Definition
For your reference, below is my solution for the API definition. Feel free to implement either the API that you have designed or use mine as the starting point:

# URL Path
POST <BASE_URL>/api/orders/computers

# Request Header
Content-Type: application/json

# Request Body
{
    "created_by": <user_id: str>,
    "status": <status_enum: str>, // QUEUED, PROCESSING, COMPLETED, FAILED, CANCELLED
    "created_at": <isoformat_timestamp: str>,
    "equipment": [
        <equipment: str>
    ]
}
# Response Body
{
    "order_id": <order_id: str>,
    "created_by": <user_id: str>,
    "status": <status_enum: str>, // QUEUED, PROCESSING, COMPLETED, FAILED, CANCELLED
    "created_at": <isoformat_timestamp: str>,
    "equipment": [
        <equipment: str>
    ]
}

# URL Path
GET <BASE_URL>/api/orders/computers

# Request Header
`Content-Type: application/json`

# Response Code
`200 OK`

# Response Body

"computer_orders": [
    {
        "order_id": <order_id: str>,
        "created_by": <user_id: str>,
        "status": <status_enum: str>,
        "created_at": <isoformat_timestamp: str>,
        "equipment": [
            <equipment: str>
        ]
    }
]



4.8 Solution: Using REST
---------------------------------------

q1
yes. For large application, things may become complex.


4.9 Using gRPC
---------------------------------------
Using gRPC With Python
Implementing gRPC with Python involves two libraries:

grpcio to run client and server code
grpcio-tools to generate definition code.

Creating a gRPC Client and Server
Define a protobuf request messages, response messages, and service in a .proto file.
Use grpcio-tools command on the .proto file to generate a pair of Python files representing the messages and the services.
Import the pair of Python files into your application logic and implement your client/server.

Example

Step 1: Define .proto file
message Item {
  string name = 1;
  string brand_name = 2;
  int32 id = 3;
  float weight = 4;
}

Store this in an item.proto file and declare a service that uses it:

syntax = "proto3";

message ItemMessage {
  string name = 1;
  string brand_name = 2;
  int32 id = 3;
  float weight = 4;
}

service ItemService {
    rpc Create(ItemMessage) returns (ItemMessage);
}

Remember: item-proto is used only to generate the Python files.

Step 2: Generate gRPC Files
Using grpcio-tools, generate a pair of files that can be directly imported into our Python code:

grpc_tools.protoc -I./ --python_out=./ --grpc_python_out=./ item.proto
The path ./, can be replaced with another path or an absolute path to your .proto file.

The files item_pb2.py and item_pb2_grpc.py should have been generated.

Step 3: Import gRPC Files
Import the files to your application to use class definitions.

import item_pb2
import item_pb2_grpc
Creating a message with data would look like the following:

item = item_pb2.ItemMessage(
               name="Hair Dryer",
               brand_name="Dry King",
               id=34,
               weight=1.2
           )

Follow Along
To follow along with the demo, you can use the starter code here: gRPC Demo Source Code

Summary
Create Protobuf File
Create item.proto file
Specify proto3 syntax
Define an ItemMessage
Define ItemService with a Create method using ItemMessage
Generate gRPC Files
Install grpc-io with pip install grpcio-tools
Verify installation with pip list
Run the grpc-io command in the same directory as item.proto. The command can be hard to remember so it's useful to save it in a README
item_pb2.py and item_pb2_grpc.py should have been created

nstall gRPC for Python
Install grpcio with pip install grpcio
This may have already been installed when grpcio-tools was installed
Generated Files
item_pb2_grpc.py and item_pb2.py should not be edited. The files even have lines that explicitly state DO NOT EDIT!.

Summary
gRPC Server
gRPC server logic is implemented in main.py
grpc is imported to use gRPC in Python code
item_pb2 and item_pb2_grpc is imported to handle the ItemMessage and ItemService that was defined in the .proto file
ItemServicer is the implementation of the ItemService protobuf stub
Create in ItemServicer defines our custom logic. It is set up in a simple manner where a Python dict is printed and returned as an item_pb2.ItemMessage object instead of an unstructured dict
The file handles a lot of boilerplate for setting up a gRPC server since we aren't using a framework like Flask that can reduce boilerplate

Running the gRPC Server
python main.py will serve the gRPC server on localhost:5005 import gprc to use gRPC

Summary
Create gRPC Client
gRPC client logic is implemented in writer.py
grpc is imported to use gRPC in Python code
item_pb2 and item_pb2_grpc is imported to handle the ItemMessage and ItemService that was defined in the .proto file. These files don't need to be regenerated.
Client is configured to send messages to localhost:5005 where the gRPC server is running.
iteM_pb2.ItemMessage object is created with expected fields and values.

Running the gRPC Client
python writer.py will run the gRPC client
Changing tabs to where the gRPC server is running, it prints the payload that was passed by the gRPC client

Showcasing Type Checking
Change the value of brand_name from a string to an integer in writer.py
python writer.py to run the gRPC client will return an error that brand_name should be a string.
New Terms

Term		Definition
grpcio		A Python library used to run gRPC client and gRPC server code
grpcio-tools	Python library of tools that help generate definition code used by gRPC



4.10 Quizzes: Using gRPC
---------------------------------------
Ensures that grpcio-tools is parsing the expected syntax



4.11 Exercise: Using gRPC
---------------------------------------
Applying Using gRPC
Using the following proto file that defines computer orders, set up a gRPC server that accepts OrderMessage's:

syntax = "proto3";

message OrderMessage {
 enum Status {
   QUEUED = 0;
   PROCESSING = 1;
   COMPLETED = 2;
   FAILED = 3;
 }

 enum Equipment {
   KEYBOARD = 0;
   MOUSE = 1;
   WEBCAM = 2;
   MONITOR = 3;
 }

 string id = 1;
 string created_by = 2;
 Status status = 3;
 string created_at = 4;
 repeated Equipment equipment = 5;
}

message Empty {

}

message OrderMessageList {
 repeated OrderMessage orders = 1;
}



4.12 Solution: Using gRPC
---------------------------------------
The code to the solution can be found here: Using gRPC Solution.

Summary
Protobuf File
proto3 is specified as the syntax
OrderMessage uses enums Status and Equipment to add string validation
Empty message is defined to help handle null values where an empty argument is passed to the service
OrderMessageList helps capture multiple OrderMessage's
OrderService defines Create and Get stubs
OrderService.Get has no argument so it uses the Empty message as its input

Generating gRPC Files
We should have run the following command (or similar) to set up the gRPC files for Python:

grpc_tools.protoc -I./ --python_out=./ --grpc_python_out=./ computer_orders.proto

The resulting computer_orders_pb2_grpc.py and computer_orders_pb2.py files can be imported into Python and leveraged with the grpc package.

Summary
Server Code
Server code is defined in main.py using mostly boilerplate code to set up a gRPC server
OrderServicer.Get returns hardcoded data by creating two order_pb2.OrderMessage objects and returning them in the OrderMessageList
OrderServicer.Create returns the same data that was passed in

Running the gRPC Server
python main.py will run the gRPC server and print its outputs

Create gRPC Client
Writer
Writer is used to demonstrate how OrderServicer.Create is called
Defined in writer.py
Creates an OrderMessage and passes it to OrderServicer.Create

Getter
Getter is used to demonstrate how OrderServicer.Get is called
Defined in getter.py
Creates an Empty message and passes it to OrderServicer.Get

Running gRPC Clients
python getter.py returns a hard-coded OrderMessageList
python writer.py returns the data that we passed in
gRPC server behavior can be validated as it prints the output


q1
yes, you need to go through a predefined "compilation" in order to use the gRPC feature.



4.13 Using Kafka
---------------------------------------
Kafka
Use Cases
Kafka is a special type of message queue that is often used to handle large volumes of data generated continuously as events.
Some examples include application logs and user activity — things that represent that "something has happened."

Architecture Overview
Kafka is a distributed system, which means that it is an application that is powered by multiple nodes.
When a producer writes data to Kafka, it stores the data inside of topics.

Topics
Topics are abstractions of Kafka where messages can be stored and referenced.
Internally, topics are distributed as partitions in different nodes and allow parallelized operations.

In practice, this may mean that a producer has a topic named "Click" that captures a user's click events on a web page

Distributed Data
Performance
A single server may be limited by its ability to handle requests
Using two servers can potentially improve a system's ability to handle requests by 2x
Since data for a topic is stored in multiple servers, multiple requests can be made in parallel for higher throughput.

Durability
A single server may have data loss when an error occurs
Storing data in multiple servers can help prevent data loss when one of the servers go down
Kafka handles the replication of data so that if a Kafka node goes down, the data is backed up and not lost.

Every time a message is written to "Click" by a producer, it is stored in a different part of Kafka.
Since they are stored in different parts of storage internally, producers and consumers can write and read different parts of a topic simultaneously.


Setup
Kafka setup is straightforward. The best way to get started with Kafka is to follow the official Apache Kafka Quickstart.

Starting Kafka Summary
Download Kafka and as a compressed .tgz file. (If you're presented with options to download the Source Download or Binary Download, choose the Source Download)
Start the Zookeeper service in the command line
Start the Kafka broker in the command line

Using Kafka Summary
Create a Kafka Topic named items using the bin/kafka-topics.sh script
Read events from the Kafka Topic items using the bin/kafka-console-consumer.sh script
Write events to the Kafka Topic items using the bin/kafka-console-producer.sh script
Write messages to Kafka using the input script
The terminal reading from Kafka will print the input that we have passed into the topic

Kafka Python
Kafka Python is a library that can be used to set up Kafka Producers or Kafka Consumers. The library is simply a client and you will need to run the Kafka broker separately.

Producers
Once a producer is configured, we can send a message with the .send() method.

The .flush() method is used to write a message immediately.

It's useful for a demo to view the results immediately.
In practice, flush() helps with performance by sending a batch of messages instead of a request for every message that is sent.

Demo Code
producer.py
from kafka import KafkaProducer


TOPIC_NAME = 'items'
KAFKA_SERVER = 'localhost:9092'

producer = KafkaProducer(bootstrap_servers=KAFKA_SERVER)

producer.send(TOPIC_NAME, b'Test Message!!!')
producer.flush()

consumer.py
from kafka import KafkaConsumer


TOPIC_NAME = 'items'

consumer = KafkaConsumer(TOPIC_NAME)
for message in consumer:
    print (message)

New Terms
Term	Definition
Topic	Kafka's abstraction of messages stored internally as distributed partitions
Producer	Generates messages to a message broker
Consumer	Receives messages from a message broker



4.14 Quizzes: Kafka
---------------------------------------
Tracking user click activity on a website
Post-processing user "likes" on a social media platform



4.15 Exercise: Setting Up and Using Kafka
---------------------------------------
Applying Kafka
We want to set up a Kafka broker on our system to handle computer orders. We will then interact with it by sending it messages.

For up-to-date instructions on installing and running Kafka, please refer to the Kafka Quickstart guide on Kafka's official website.





4.16 Solution: Setting Up and Using Kafka
---------------------------------------
Download Kafka
Downloading the latest Kafka release following the instructions Get Kafka. This gives us a kafka_*.tgz file. Once we decompress this file, we have a directory containing a handful of files that can be used with Kafka.

Running Kafka
Run the Kafka broker following the instructions Start the Kafka Environment


Create a Topic

bin/kafka-topics.sh --create --topic orders --bootstrap-server localhost:9092


Load a Consumer

bin/kafka-console-consumer.sh --topic orders --from-beginning --bootstrap-server localhost:9092

Write a Message
This will load a client where you can submit messages with every newline.

bin/kafka-console-producer.sh --topic orders --bootstrap-server localhost:9092


q1
it takes a few steps to setup and run Kafka. In term of behavior, they are the same. but python application allow more flexibility.

A Python application runs inside of a controlled environment with Python code. Running the Kafka broker involves system-level dependencies and is run as a system process.




