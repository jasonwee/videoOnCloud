date start : 17 october 2021


4.1 Lesson Overview
---------------------------------------
Lesson Outline
This lesson is all about tracing. Tracing will allow us to get performance data on our applications, particularly on the latency of the key processes within them.

Big Picture: What is tracing? First we will talk about the underlying concept of tracing and how it is different from logs. In particular, we will consider why tracing is increasingly popular in diagnosing latency issues.
Distributed Tracing. In order to do tracing on our Kubernetes cluster, we need an approach to tracing that can handle microservices. This is called distributed tracing. We will explain what distributed tracing is in the context of Kubernetes applications and why this is such a useful tool.
Jaeger. Our tool for distributed tracing is Jaeger. We will discuss the key features of Jaeger as well as the main standards it uses, which are the OpenTracing and OpenTelemetry models.
Python Application Tracing. With Prometheus and Grafana, once we installed them they were pretty much ready to go. In contrast, in order to do tracing with Jaeger, we have to actually add code into the application itself to run a trace. We will walk through how to do this with Python applications.
Revisiting Logging. Finally, we will revisit logging. Although tracing is incredibly useful for issues involving latency, this doesn't mean that you should abandon logging. We will look at some use cases when you will want to utilize logs and consider how how logs are still useful in tracing.



4.2 Big Picture: What is Tracing?
---------------------------------------
A trace is a mock request that goes through services and records its performance as it executes.

A trace tells you:

What was executed
How long it took

q1
Tracing is different from event logging because…
It logs low-level information



4.3 Distributed Tracing
---------------------------------------
A key tool we'll want to make use of when monitoring performance on a cluster is distributed tracing. Simply put, distributed tracing is tracing for microservices.

With distributed tracing, we are able follow the execution of a request as it goes through all of the relevant services. In the world of microservices, it is usually the case that a single function such as clicking "Login" will trigger multiple services—and we need to be able to trace the execution through all of these.

Distributed tracing uses a unit of work known as a span. A single trace can be made up of multiple spans that are all linked together.

Spans are the units of work that make up a trace; spans are objects that represent a single part of the process being traced.

Anatomy of a Span Object
Each span object has the following components:

Tags for labeling – these are key-value pairs that you can use to label your span (e.g., db.instance: "users") to make your traces more human readable.
Trace ID is the unique identifier of the trace
Span ID is the unique identifier of the span
Message is the actual error message
Span Context is persistent metadata
Scope is the start and stop

q1
See if you can match these tracing concepts with their descriptions:

Unit of work that makes up a trace.                     Span
Formalizes the activation and deactivation of a Span    Scope
Key-value pairs that enable user-defined annotation     Tags
The way Jaeger presents execution requests              Trace


q2
Choose two items that you would see in a SpanContext.
trace_id
Baggage Items

￼
Additional Resources
If you would like to learn more about Jaeger's inner workings, you can check out Jaeger's website here.



4.4 Exercise: Distributed Tracing
---------------------------------------
On a day-to-day basis, you won't be creating traces—more commonly, you will be analyzing tracing data. Thus, the developer would more commonly be creating the traces.

However, you may be expected to report back when a service isn't meeting an SLO. And this may involve looking at tracing data, so it is important to understand what a trace looks like.

With that in mind, this page will give you some familiarity with the JSON payloads and the components of a standard trace.

q1
Using the typical "key:value" format that you would see in JSON or a Python dictionary, match tracing tags with the proper value.

http.method              GET
hostname                 my-sample-app-748f899b57-gzwph
pod.namespace            default
container.name           my-sample-app

q2
Here are some more. Can you match these up as well?

http.url   http://localhost:8888/
Duration   1.22s
Span ID    244bdabe60098ac5

q3
If you saw a span tag called span.kind, which item would not be an accurate value?
endpoint



4.5 Jaeger
---------------------------------------
Jaeger
In this course, our key tool for tracing is Jaeger.

Jaeger is an open source distributed tracing system.

OpenTracing and OpenTelemetry
Jaeger uses the OpenTracing data model:

OpenTracing is the data model used to structure spans and traces.
OpenTelemetry is the future of OpenTracing. It was created when OpenCensus merged with OpenTracing.
The OpenTracing model is an industry standard and has native support in many frameworks, including Flask, gRPC, and Rails.

Components of Jaeger
Client is the code that you install to execute the trace.
Agent is the daemon that listens to the UDP calls and sends it to collector.
Collector receives the trace and processes it.
Note that Jaeger's storage is a pluggable component with Cassandra, ElasticSearch and Kafka. By default, it uses in memory storage but you wouldn’t do that in production as it’s not durable.
Query allows you to query collected traces.
UI is the built in Web UI for interacted with Jaeger Query.
Ingester reads from a Kafka topic and writes to another storage backend. This is only necessary if you are using Kafka topics to store data.

q1
What is the underlying API for Jaeger's tracing?
OpenTracing


q2
Besides Elastic Search, which two of the following are supported data backends for Jaeger's collector?
cassandra
kafka


Additional Resources
If you'd like to read more about OpenTracing, OpenCensus, and OpenTelemetry, you may want to check out this blog post from New Relic.



4.6 Exercise: Jaeger
---------------------------------------
apiVersion: apps/v1
kind: Deployment
metadata:
  name: myapp
  annotations: "sidecar.jaegertracing.io/inject": "true"
spec:
  selector:
    matchLabels:
      app: myapp
  replicas: 1
  template:
    metadata:
      labels:
        app: myapp
    spec:
      containers:
      - name: myapp
        image: acme/myapp:myversion
        ports:
        - containerPort: 80



4.7 Python Application Tracing
---------------------------------------
Python Application Tracing
Again, you as the SRE likely won't be the one adding the tracing code to the application. That said, you should be familiar with how it works, so we'll go over some of the basics here.

q1
What is the name of the jaeger library in Python?
jaeger-client


q2
What is the name of the span?
get-python-jobs

q3
For the quiz below. please refer to this code (courtesy of opentracing.io):
Code is pulling job posts from Github that relate to Python.
For each page collected, it is creating a span to measure speed.



4.8 Exercise: Python Application Tracing
---------------------------------------
import logging
from jaeger_client import Config
from opentracing.ext import tags
from opentracing.propagation import Format
import requests

def init_tracer(service):
    logging.getLogger('').handlers = []
    logging.basicConfig(format='%(message)s', level=logging.DEBUG)
    config = Config(
        config={
            'sampler': {
                'type': 'const',
                'param': 1,
            },
            'logging': True,
        },
        service_name=service,
    )
    # this call also sets opentracing.tracer
    return config.initialize_tracer()

tracer = init_tracer('first-service')

def test():
    # Add your test function here
    with tracer.start_span('TestSpan') as span:
        req = requests.get('https://udacity.com')
        span.set_tag('http.method;', req)
        def format():
            with tracer.start_span('my-test-span') as span:
                try:
                    print("success!")
                except:
                    print("try again")

if __name__ == "__main__":
    test()


root@6bc3c1d4828b:/home/workspace# python app.py 
Initializing Jaeger Tracer with UDP reporter
Using sampler ConstSampler(True)
opentracing.tracer initialized to <jaeger_client.tracer.Tracer object at 0x7f4ae76ce588>[app_name=first-service]
Starting new HTTPS connection (1): udacity.com
https://udacity.com:443 "GET / HTTP/1.1" 301 0
Starting new HTTPS connection (1): www.udacity.com
https://www.udacity.com:443 "GET / HTTP/1.1" 200 48682
Reporting span 20d747fc4b0deea3:b30f8fed799506db:0:1 first-service.TestSpan
root@6bc3c1d4828b:/home/workspace# 



4.9 Challenge: More Application Tracing
---------------------------------------
Challenge: More Python Application Tracing
As mentioned earlier, reliability engineers don't typically work with the production code. They may develop code and additional tooling to make their jobs better, but in terms of what's shipped to the customer, that usually lies squarely with the developers.

For this reason, it will generally be the developers who add tracing components to the code. That being said, maybe you are curious and want to see more about the development side. If so, you can try out this optional challenge exercise.

You will need to have a few things to do this:

Your own container registry (GitHub Repo, DockerHub, etc.).
Intermediate level knowledge of Python (e.g., you can write the code for a simple Python app).
Kubernetes Cluster (ideally your K3s cluster on Vagrant).
Jaeger setup on cluster.
You can find the necessary files at this GitHub Repo.


Now that you have the deployment good to go, it is up to you to find a way to improve the latency of the application. There are many ways to do this and you are welcome to take any approach that achieves the goal of reducing the latency. I've provided one possible approach below, but your solution may be quite different!

When you change the code, be sure to tag it differently from the first docker build. Something like :v2 will do the trick. You will also need to update the deployment.sample.yaml to reflect the new tags.

Sample Solution
There are a myriad ways you can accomplish this task. One way I did this was to utilize the Flask-OpenTracing library, which simplifies the code that I need to add. This block of code will collect the traces that I need:

config = Config(
    config={
        'sampler':
        {'type': 'const',
         'param': 1},
                        'logging': True,
                        'reporter_batch_size': 1,}, 
                        service_name="service")
jaeger_tracer = config.initialize_tracer()
tracing = FlaskTracing(jaeger_tracer, True, app)
This acts as more of a "catch-all" for your application, so it won't necessarily create child spans—but it gives us results that we can use.

Using Redis
Looking at the app.py file, you may have noticed an endpoint named "redis". Redis is a popular memory store database. It uses a simple key-value structure to store data in memory.

in the k8s directory, you will see a subdirectory called redis. You deploy both yaml files into your cluster in order to enable a Redis deployment. Then, if you like, you can create a trace on the redis endpoint and diagnose why the database write is taking so long.



4.10 Revisiting Logging
---------------------------------------
q1
If a trace seemed "inconclusive", what step do you think you should take first?
Check other logs


Logging is great when it comes to trying to collect runtime errors. While tracing is great at collecting latency information, you will still benefit from collecting runtime errors such as 500 responses.

The bottom line is that tracing doesn't replace logging—rather, it supplements it.


q2
Your application is showing a 500 error, would you choose to log or to trace?
log


Additional Resources
When looking at logs, it can be useful to use a log aggregation tool, such as Grafana Loki. If you're curious, you can read more about this in this article from Grafana.
If you would like to learn more about the differences between tracing and logging, you can check out this article on distributed tracing versus logging.




