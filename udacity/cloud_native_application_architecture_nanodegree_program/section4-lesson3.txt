date start : 14 october 2021


3.1 Lesson Overview
---------------------------------------
Introduction to SLIs, SLOs, and Error Budgets

Lesson Outline
This lesson is all about reliability metrics. In order to observe performance, we first need to get clear on how we are defining and measuring it, and that's what we'll cover here.

Defining performance. The first thing we need to do is define what we mean by site reliability or performance. We will talk about performance in terms of providing a certain level of service, and we'll go over what are called the four golden signals that are used in site reliability modeling.
Service-Level Objectives (SLOs). We also need a clear objective or goal, and this is where Service-Level Objectives (or SLOs) come in. We will talk about what SLOs are and what factors to consider when setting them.
Service-level indicators (SLIs) . Once we have a clear definition and objective for the level of performance we want to deliver, we need to consider how we will actually measure this performance. This is done using Service-Level Indicators or SLIs.
Error Budgets. Since we cannot guarantee 100% performance, we need to plan for errors. For example, if we are OK with 99% reliability on a metric, that means we have an error budget of 1%. We are deciding that if things get any worse than that 1%, this is a signal to us that an improvement is needed.
Building SLAs. Finally, we will bring this all together and examine Service-Level Agreements or SLAs. While you personally won’t have to worry about SLAs as an SRE, it is important to understand the context of SLAs as it does play a part in the overall SRE model.



3.2 Big Picture: Measuring Performance
---------------------------------------
Remember, the main value that we as site reliability engineers add, that is not provided by other roles like sysadmins and DevOps engineers, is that we ensure that a deployed application has a good level of performance for the customer. We call this the service level.

The service level is the degree (i.e. level) of performance that an application (or service) provides to the user.

Typically, service is defined in terms of four core properties, called the Four Golden Signals:

Latency — The time taken to serve a request (usually measured in ms).
Traffic — The amount of stress on a system from demand (such as the number of HTTP requests/second).
Errors — The number of requests that are failing (such as number of HTTP 500 responses).
Saturation — The overall capacity of a service (such as the percentage of memory or CPU used).
These signals are generally considered the pillars of SRE best practices because most issues will fall into one of these four categories. By defining performance in these terms, it’s easier to plan, identify, and execute when we are building our goals for our service level.


q1
Below are the three roles we just discussed. Can you match each with the area they focus on most?
Performance-focused and customer-centric              site reliability
Focused more on infrastructure as code                devops
Provisioning hardware and managing infrastructure     sysadmin


q2
Below are the Four Golden Signals. Can you match each of them with an example of how we would measure that signal?
Number of milliseconds taken to serve a request   latency
Percentage of CPU used.                           saturation
Number of HTTP requests/second.                   traffic
Number of HTTP 500 responses.                     errors


Additional Resources
If you would like to learn more about Service Level Objects, check out this chapter on SLOs in the Google Site Reliability Engineering book.



3.3 Service-Level Objectives (SLOs)
---------------------------------------
What is an SLO?
Now that we are clear about the Four Golden Signals, we are ready to set some specific objectives. These are called our Service-Level Objectives.

A Service-Level Objective (SLO) is a measurable goal set by the SRE team to ensure a standard level of performance during a specified period of time.

For example, we might specify an SLO like "99.99% uptime per month". Typically SLOs are measured in terms of latency and uptime, although it is not unusual for SRE teams to add additional goals.

User Journey
When creating an SLO, it is important to be customer-centric. If we keep user experience and expectations at the center of our planning, we will have a strong SLO strategy. A common way to make sure you are customer-centered in your strategy is to map out a user journey for the application.

Here is a process you can follow to help ensure your SLOs are customer-centric:

Do what a user would do. You will want to stress test the product and use it the same way the user would.
Map the journey to services. Once you understand the customer journey, you can map out what that journey looks like in terms of what specific services are used.
Find the metrics. Once you know what services are involved, you can identify the metrics for those services.
Determine goals. Once we have relevant metrics in mind, it is relatively easy to determine what goals would be reasonable and would tap into these metrics.
Design formal SLOs. Once you have your goals, it's time to formalize them as SLOs. These SLOs will then appear in your team charter, and you and your team will have a clear objective that you can be accountable for.

Basing your SLOs on a user journey is very important because, at the end of the day, the person who ultimately cares about performance is the user

q1
A key aspect of an SLO is that they involve measurable objectives. Below are some different metrics we can use when creating SLOs. Can you match each metric with the correct description?

Response time of requests                  latency
The amount of failures in a unit of time   failure rate
Average bandwidth                          network capacity
Time a service is active                   uptime


q2
Which of the following are examples of SLOs?
99.5% of requests return in 50ms in the past month.
99.99% of response codes are 200s or 300s per month


q3
Your company is working on modernizing their applications. This decision was triggered by a report that customers feel the application is "too slow". Thus, measuring speed and performance is of great importance.

Use the matching quiz to order the steps you would need to take to help your customers.

first   document user journye by business impact
second  identify services involved in journey
third   determine metrics to use to measure customer experience
fourth  determine goals


Additional Resources
If you would like to learn more about Service Level Objectives, check out this chapter on SLOs in the Google Site Reliability Engineering book.



3.4 Exercise: SLOs
---------------------------------------
helpful to question by clients
ensure complaints are deal with apropriately
ensure empty grocery item are refill

latency
bandwidth
uptime



3.5 Service-Level Indicators (SLIs)
---------------------------------------
We've just learned what SLOs are and how we can use them to set goals. But how do we know when we’ve reached that goal? This is where Service-Level Indicators come in.

A Service-Level Indicator (SLI) is a specific metric used to measure the performance of a service.

Sometimes the term SLI is used to refer to the general metric—such as uptime or latency. But really what we need in the end is an actual measurement. For example, suppose that your team has the following SLO:

The application will have an uptime of 99.9% during the next year.

In this case, your SLI would be the actual measurement of the uptime. Perhaps during that year, you actually achieved 99.5% uptime or 97.3% uptime. These measurements are your SLIs—they indicate the level of performance your service actually exhibited, and show you whether you achieved your SLO (in this case, the SLIs show that performance fell short of your objective).

Notice that the above example is a ratio. Specifically, it is a ratio of a measurement to a given amount of time (the measured uptime per year). When you think of SLIs, think in terms of ratios like this—a ratio of X / Y, where X is usually a measurement and Y is usually an amount of time.

q1
The terminology surrounding SLOs, SLIs, and signals can get a little confusing.I t can be a little tricky to see the distinction between them. Below are some examples. Can you identify which is which?

The average time taken to return a request will be less than 200 ms, during the month of May.       SLO

The average time taken to return a request during the month of May was 194 ms.                      SLI

Latency                                                                                             General type of metric used



Additional Resources
If you would like to learn more about the distinction between SLOs and SLIs, you may want to check out:

This blog post from Elisa Binette on best practices for setting SLOs and SLIs
This blog post from Google Cloud Platform on SLIs, SLOs, and SLAs



3.6 Exercise: SLIs
---------------------------------------
q1
Reflect on SLIs
Let's get some practice to make sure that we understand SLIs. Like we did with SLOs, let's start with a non-technical, everyday scenario.

Suppose that you are monitoring the performance of services at a fast food restaurant. See if you can describe 3–5 SLIs that you could use to measure performance.

speed of customer order receive until customer order is served. customer waiting line. food replenish rate

Your answers will most likely differ from mine, but here are some reasonable examples that you might have picked:

Number of orders filled/hour.
Number of 5-star ratings/day.
Number of returned orders/week.
Hamburgers sold/month.
Percentage of late orders (fulfillment time >10 minutes)/hour.

Remember, when you think of SLIs, think in terms of ratios—a number of X / Y, where X is a measurement and Y is (typically) an amount of time.


q2
Suppose you have the following SLO:

HTTP requests will take 10ms or less to complete (on average) each month.

When you look at your SLI, you are finding that in actuality it takes around 20ms. Your team was able to address the issue with a rollback. What next step should be taken?


Perform a postmortem to identify the root cause



3.7 Error Budgets
---------------------------------------
No matter how hard we try, inevitably there will be some downtime. For that reason, we give ourselves a buffer or error budget.

An error budget is a buffer in an SLO that allows for a small amount of error.

Error budgets can be visualized with this formula:

Error budget = 100% – SLO

For example, when we state an SLO like:

The application will have 99.9% uptime each month.

We are giving ourselves a buffer of 0.1% of the month to experience downtime—meaning that experiencing a small—perhaps unavoidable—amount of downtime will not indicate we failed to meet the objective.


q1
If we have an SLO that states that we will have an uptime of 99.95%, what is our error budget?
0.05%


q2
Suppose you find that you are exceeding your error budget. Below are some events that might cause this to happen. For some of them, you should take immediate action or re-evaluate your SRE strategy. For others, you should not take any action.

For which of these should you take action or re-evaluate your strategy?

(Select two correct answers.)

A postmortem reveals an excessively restrictive policy
A bug in the code


You will always want to do a postmortem to figure out what happened. Sometimes you will find instances where an SLO is too restrictive and you may need to re-evaluate your strategy.

And of course, if there is a bug in the code, you should address it, since the service itself shouldn't be causing failures.



3.8 Exercise: Error Budgets
---------------------------------------
q1
QUESTION 1 OF 2
Suppose we set the following SLO:

The application will be available 97% of the time during each month.

This past month, you received 10,500,000 HTTP requests. How many requests can be HTTP 500 responses?

315,000


q2
Your error budget is 25 minutes of downtime per month. This past month you had 45 minutes of downtime. It was determined that the issue was related to your database caching maxing out its disk space every other week. You are asked to make some recommendations on how we can address this in the future. Which are the best ideas?

(Select all that apply.)

Determine what occurs every other week
Find what services are using the cache 



3.9 SLAs
---------------------------------------
Generally speaking, SLAs are more of a concern for the customers, business development teams, and legal departments than the SRE team.

Although you as an SRE typically won't have to work directly with Service-Level Agreements on a daily basis, it's still good to have an awareness of them.

Service-Level Agreements (SLAs) are legally binding contracts that guarantee a service level to the customer

If the SLA is not met, typically the company will provide some form of compensation to the customer.

q1
Which one of these would typically be out of scope for an SLA for a Platform as a Service company?

The service that your customer deploys.



3.10 Lesson Review
---------------------------------------
Lesson Outline
This lesson was all about reliability metrics. In order to observe performance, we first needed to get clear on how we are defining and measuring it, and that's what we covered in this lesson.

Defining performance. The first thing we needed to do was define what we mean by site reliability or performance. We talked about performance in terms of providing a certain level of service, and we went over what are called the four golden signals that are used in site reliability modeling.
Service-Level Objectives (SLOs). We also needed a clear objective or goal, and this is where Service-Level Objectives (or SLOs) come in. We talked about what Service Level Objectives are and what factors to consider when setting them.
Service-level indicators (SLIs) . Once we have a clear definition and objective for the level of performance we want to deliver, we need to consider how we will actually measure this performance. This is done using service-level indicators or SLIs.
Error Budgets. Since we cannot guarantee 100% performance, we need to plan for errors. For example, if we are OK with 99% reliability on a metric, that means we have an error budget of 1%. We are deciding that if things get any worse than that 1%, this is a signal to us that an improvement is needed.
Building SLAs. Finally, we brought this all together and examined Service-Level Agreements (SLAs). While you personally won’t have to worry about SLAs in your role as an observability engineer, it is important to understand the context of SLAs as it does play a part in the overall SRE model.


