date start : 21 july 2021


3.1 Machine Learning with AWS
---------------------------------------
The AWS achine learning mission is to put machine learning in the hands of every developer.

AWS offers the broadest and deepest set of artificial intelligence (AI) and machine learning (ML) services with unmatched flexibility.
You can accelerate your adoption of machine learning with AWS SageMaker. Models that previously took months to build and required specialized expertise can now be built in weeks or even days.
AWS offers the most comprehensive cloud offering optimized for machine learning.
More machine learning happens at AWS than anywhere else.




3.2 Lesson Overview
---------------------------------------


3.3 AWS Account Requirements
---------------------------------------
AWS Account Requirements
An AWS account is required
To complete the exercises in this course, you need an AWS Account ID.

To set up a new AWS Account ID, follow the directions in How do I create and activate a new Amazon Web Services account?

You are required to provide a payment method when you create the account. To learn about which services are available at no cost, see the AWS Free Tier documentation.

Will these exercises cost anything?
This lesson contains many demos and exercises. You do not need to purchase any AWS devices to complete the lesson. However, please carefully read the following list of AWS services you may need in order to follow the demos and complete the exercises.

Train your computer vision model with AWS DeepLens (optional)
To train and deploy custom models to AWS DeepLens, you use Amazon SageMaker. Amazon SageMaker is a separate service and has its own service pricing and billing tier. It's not required to train a model for this course. If you're interested in training a custom model, please note that it incurs a cost. To learn more about SageMaker costs, see the Amazon SageMaker Pricing.
Train your reinforcement learning model with AWS DeepRacer
To get started with AWS DeepRacer, you receive 10 free hours to train or evaluate models and 5GB of free storage during your first month. This is enough to train your first time-trial model, evaluate it, tune it, and then enter it into the AWS DeepRacer League. This offer is valid for 30 days after you have used the service for the first time.
Beyond 10 hours of training and evaluation, you pay for training, evaluating, and storing your machine learning models. Charges are based on the amount of time you train and evaluate a new model and the size of the model stored. To learn more about AWS DeepRacer pricing, see the AWS DeepRacer Pricing
Generate music using AWS DeepComposer
To get started, AWS DeepComposer provides a 12-month Free Tier for first-time users. With the Free Tier, you can perform up to 500 inference jobs translating to 500 pieces of music using the AWS DeepComposer Music studio. You can use one of these instances to complete the exercise at no cost. To learn more about AWS DeepComposer costs, see the AWS DeepComposer Pricing.
Build a custom generative AI model (GAN) using Amazon SageMaker (optional)
Amazon SageMaker is a separate service and has its own service pricing and billing tier. To train the custom generative AI model, the instructor uses an instance type that is not covered in the Amazon SageMaker free tier. If you want to code along with the instructor and train your own custom model, you may incur a cost. Please note, that creating your own custom model is completely optional. You are not required to do this exercise to complete the course. To learn more about SageMaker costs, see the Amazon SageMaker Pricing.


3.4 Computer Vision and Its Applications
---------------------------------------
How computer vision got started
Early applications of computer vision needed hand-annotated images to successfully train a model.
These early applications had limited applications because of the human labor required to annotate images.

Three main components of neural networks
Input Layer: This layer receives data during training and when inference is performed after the model has been trained.
Hidden Layer: This layer finds important features in the input data that have predictive power based on the labels provided during training.
Output Layer: This layer generates the output or prediction of your model.

Modern computer vision
Modern-day applications of computer vision use neural networks call convolutional neural networks or CNNs.
In these neural networks, the hidden layers are used to extract different information about images. We call this process feature extraction.
These models can be trained much faster on millions of images and generate a better prediction than earlier models.

How this growth occured
Since 2010, we have seen a rapid decrease in the computational costs required to train the complex neural networks used in computer vision.
Larger and larger pre-labeled datasets have become generally available. This has decreased the time required to collect the data needed to train many models.



Image classification is the most common application of computer vision in use today. Image classification can be used to answer questions like What's in this image? This type of task has applications in text detection or optical character recognition (OCR) and content moderation.
Object detection is closely related to image classification, but it allows users to gather more granular detail about an image. For example, rather than just knowing whether an object is present in an image, a user might want to know if there are multiple instances of the same object present in an image, or if objects from different classes appear in the same image.
Semantic segmentation is another common application of computer vision that takes a pixel-by-pixel approach. Instead of just identifying whether an object is present or not, it tries to identify down the pixel level which part of the image is part of the object.
Activity recognition is an application of computer vision that is based around videos rather than just images. Video has the added dimension of time and, therefore, models are able to detect changes that occur over time


New Terms
Input Layer: The first layer in a neural network. This layer receives all data that passes through the neural network.
Hidden Layer: A layer that occurs between the output and input layers. Hidden layers are tailored to a specific task.
Output Layer: The last layer in a neural network. This layer is where the predictions are generated based on the information captured in the hidden layers.


https://www.awsdeeplens.recipes/
https://aws.amazon.com/blogs/machine-learning/
https://aws.amazon.com/blogs/machine-learning/category/artificial-intelligence/aws-deeplens/
https://docs.aws.amazon.com/deeplens/latest/dg/deeplens-getting-started.html


3.5
---------------------------------------
AWS DeepLens
AWS DeepLens allows you to create and deploy end-to-end computer vision–based applications. The following video provides a brief introduction to how AWS DeepLens works and how it uses other AWS services.

AWS DeepLens is a deep learning–enabled camera that allows you to deploy trained models directly to the device. You can either use sample templates and recipes or train your own model.

The AWS DeepLens device
The AWS DeepLens camera is powered by an Intel® Atom processor, which can process 100 billion floating-point operations per second (GFLOPS). This gives you all the computing power you need to perform inference on your device. The micro HDMI display port, audio out, and USB ports allow you to attach peripherals, so you can get creative with your computer vision applications.

You can use AWS DeepLens as soon as you register it.

How AWS DeepLens works
AWS DeepLens is integrated with multiple AWS services. You use these services to create, train, and launch your AWS DeepLens project. You can think of an AWS DeepLens project as being divided into two different streams as the image shown above.

First, you use the AWS console to create your project, store your data, and train your model.
Then, you use your trained model on the AWS DeepLens device. On the device, the video stream from the camera is processed, inference is performed, and the output from inference is passed into two output streams:
Device stream – The video stream passed through without processing.
Project stream – The results of the model's processing of the video frames.


3.6 A sample project with aws deeplens
---------------------------------------
Machine Learning workflow review
The machine learning workflow contains several steps first introduced in Lesson 2. Let's briefly review the different steps and how they relate to the AWS DeepLens project.

1. Define the problem.
Using machine learning, we want to improve how trash is sorted. We're going to identify objects using a video stream, so we identify this as a computer vision–based problem.
We have access to data that already contains the labels, so we classify this as a supervised learning task.

2. Build the dataset.
Data is essential to any machine learning or computer vision–based project. Before going out and collecting lots of data, we investigate what kinds of data already exist and if they can be used for our application.
In this case, we have the data already collected and labeled.

3. Train the model.
Now that we have our data secured for this project, we use Amazon SageMaker to train our model. We cover specifics about this process in the demonstration video.

4. Evaluate the model.
Model training algorithms use loss functions to bring the model closer to its goals. The exact loss function and related details are outside the scope of this class, but the process is the same.
The loss function improves how well the model detects the different class images (compost, recycling, and landfill) while the model is being trained.

5. Use the model.
We deploy our trained model to our AWS DeepLens device, where inference is performed locally.



3.7 Quiz: Computer Vision
---------------------------------------
object deteciton , Great job! Object detection can be used to not only count the number of objects in an image but also to identify different classes present in an image.

image classification

Semantic (instance) segmentation : Nice job! Yes! Semantic segmentation is best used to identify the exact location (pixel) of an object in an image.

instance (semantic) segmentation

object detection

object detection , semantic (instance) segmentation

image classification


3.
---------------------------------------


3.
---------------------------------------


3.
---------------------------------------



