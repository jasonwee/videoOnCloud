date start : 01 july 2021


2.1 Lesson Outline
---------------------------------------
It is the engine behind the recent advancements in industries such as autonomous vehicles.
It allows for more accurate and rapid translation of the text into hundreds of languages.
It powers the AI assistants you might find in your home.
It can help improve worker safety.
It can speed up drug design.


Differentiate between supervised learning and unsupervised learning.
identify problems that can be solved with machine learning.
describe commonly used algorithms including linear regression, logistic
regression, and k-means
describe how model training and testing works.
evaluate the performance of a machine learning model using metrics.


2.2 What is Machine Learning?
---------------------------------------
What is Machine Learning?
Machine learning (ML) is a modern software development technique and a type of artificial intelligence (AI) that enables computers to solve problems by using examples of real-world data. It allows computers to automatically learn and improve from experience without being explicitly programmed to do so.

In supervised learning, every training sample from the dataset has a corresponding label or output value associated with it. As a result, the algorithm learns to predict labels or output values. We will explore this in-depth in this lesson.
In unsupervised learning, there are no labels for the training data. A machine learning algorithm tries to learn the underlying patterns or distributions that govern the data. We will explore this in-depth in this lesson.
In reinforcement learning, the algorithm figures out which actions to take in a situation to maximize a reward (in the form of a number) on the way to reaching a specific goal. This is a completely different approach than supervised and unsupervised learning. We will dive deep into this in the next lesson.

Machine learning, or ML, is a modern software development technique that enables computers to solve problems by using examples of real-world data.

In supervised learning, every training sample from the dataset has a corresponding label or output value associated with it. As a result, the algorithm learns to predict labels or output values.

In reinforcement learning, the algorithm figures out which actions to take in a situation to maximize a reward (in the form of a number) on the way to reaching a specific goal.

In unsupervised learning, there are no labels for the training data. A machine learning algorithm tries to learn the underlying patterns or distributions that govern the data.



2.3 components of machine learning
---------------------------------------
Nearly all tasks solved with machine learning involve three primary components:

A machine learning model
A model training algorithm
A model inference algorithm

A model is an extremely generic program(or block of code), made specific by the data used to train it. It is used to solve different problems.

Which of the following are the primary components used in machine learning?
A machine learning model
A model training algorithm
A model inference algorithm

￼

A model is an extremely generic program, made specific by the data used to train it.

Model training algorithms work through an interactive process where the current model iteration is analyzed to determine what changes can be made to get closer to the goal. Those changes are made and the iteration continues until the model is evaluated to meet the goals.

Model inference is when the trained model is used to generate predictions.


2.4 Quiz: What is Machine Learning?
---------------------------------------
false



2.5 Introduction to Machine Learning Steps
---------------------------------------
step one   : define the problem
step two   : build the dataset
step three : train the model
step four  : evaluate the model
step five  : inference (use the model)


2.6 Define the problem
---------------------------------------
A task is supervised if you are using labeled data. We use the term labeled to refer to data that already contains the solutions, called labels.

A task is considered to be unsupervised if you are using unlabeled data. This means you don't need to provide the model with any kind of label or solution while the model is being trained.




In supervised learning, there are two main identifiers you will see in machine learning:

A categorical label has a discrete set of possible values. In a machine learning problem in which you want to identify the type of flower based on a picture, you would train your model using images that have been labeled with the categories of flower you would want to identify. Furthermore, when you work with categorical labels, you often carry out classification tasks*, which are part of the supervised learning family.
A continuous (regression) label does not have a discrete set of possible values, which often means you are working with numerical data. In the snow cone sales example, we are trying to predict the number* of snow cones sold. Here, our label is a number that could, in theory, be any value.


answer:
supervised Learning
unsupervised learning


Terminology
Clustering. Unsupervised learning task that helps to determine if there are any naturally occurring groupings in the data.
A categorical label has a discrete set of possible values, such as "is a cat" and "is not a cat."
A continuous (regression) label does not have a discrete set of possible values, which means possibly an unlimited number of possibilities.
Discrete: A term taken from statistics referring to an outcome taking on only a finite number of values (such as days of the week).
A label refers to data that already contains the solution.
Using unlabeled data means you don't need to provide the model with any kind of label or solution while the model is being trained.


2.7 Quiz: Define the Problem
---------------------------------------
2,4

Correct! Both answers chosen here involve trying to predict some unknown continuous attribute about your data.

Remember: Classification tasks involve predicting some unknown categorical attribute about your data.

Regression tasks involve predicting some unknown continuous attribute about your data.

Clustering tasks involve exploring how your data might be grouped together


all 3


2.8 Build a Dataset
---------------------------------------

Summary statistics
Models can assume how your data is structured.

Now that you have some data in hand it is a good best practice to check that your data is in line with the underlying assumptions of your chosen machine learning model.

With many statistical tools, you can calculate things like the mean, inner-quartile range (IQR), and standard deviation. These tools can give you insight into the scope, scale, and shape of the dataset.


Terminology
Impute is a common term referring to different statistical tools which can be used to calculate missing values from your dataset.
Outliers are data points that are significantly different from others in the same sample.


2.9 Quiz: Build a Dataset
---------------------------------------
false : Nicely done! A supervised learning problem uses labeled data, and an unsupervised learning problem uses unlabeled data.

false : Correct! Because models are made specific by the data required to train them, the quality of the data is very important to the overall success of your project.

true : True or false: Data needs to be formatted so that is compatible with the model and model training algorithm you plan to use.

false : Correct! Tools from the statistics can also be used to check for outliers.

false : Correct. You should periodically review the data coming into the model. When reviewing, you should check for the same things when you built your dataset.


2.10 Model Training
---------------------------------------
Training dataset: The data on which the model will be trained. Most of your data will be here. Many developers estimate about 80%.
Test dataset: The data withheld from the model during training, which is used to test how well your model will generalize to new data.

Model parameters: Model parameters are settings or configurations the training algorithm can update to change how the model behaves. Depending on the context, you’ll also hear other more specific terms used to describe model parameters such as weights and biases. Weights, which are values that change as the model learns, are more specific to neural networks.
Loss function: A loss function is used to codify the model’s distance from this goal. For example, if you were trying to predict a number of snow cone sales based on the day’s weather, you would care about making predictions that are as accurate as possible. So you might define a loss function to be “the average distance between your model’s predicted number of snow cone sales and the correct number.” You can see in the snow cone example this is the difference between the two purple dots.

The end-to-end training process is

Feed the training data into the model.
Compute the loss function on the results.
Update the model parameters in a direction that reduces loss.


Remember the following advice when training your model.

Practitioners often use machine learning frameworks that already have working implementations of models and model training algorithms. You could implement these from scratch, but you probably won't need to do so unless you’re developing new models or algorithms.
Practitioners use a process called model selection to determine which model or models to use. The list of established models is constantly growing, and even seasoned machine learning practitioners may try many different types of models while solving a problem with machine learning.
Hyperparameters are settings on the model which are not changed during training but can affect how quickly or how reliably the model trains, such as the number of clusters the model should identify.
Be prepared to iterate.


Linear models
One of the most common models covered in introductory coursework, linear models simply describe the relationship between a set of input numbers and a set of output numbers through a linear function (think of y = mx + b or a line on a x vs y chart).

Classification tasks often use a strongly related logistic model, which adds an additional transformation mapping the output of the linear function to the range [0, 1], interpreted as “probability of being in the target class.” Linear models are fast to train and give you a great baseline against which to compare more complex models. A lot of media buzz is given to more complex models, but for most new problems, consider starting with a simple model.

Tree-based models
Tree-based models are probably the second most common model type covered in introductory coursework. They learn to categorize or regress by building an extremely large structure of nested if/else blocks, splitting the world into different regions at each if/else block. Training determines exactly where these splits happen and what value is assigned at each leaf region.

For example, if you’re trying to determine if a light sensor is in sunlight or shadow, you might train tree of depth 1 with the final learned configuration being something like if (sensor_value > 0.698), then return 1; else return 0;. The tree-based model XGBoost is commonly used as an off-the-shelf implementation for this kind of model and includes enhancements beyond what is discussed here. Try tree-based models to quickly get a baseline before moving on to more complex models.

Deep learning models
Extremely popular and powerful, deep learning is a modern approach based around a conceptual model of how the human brain functions. The model (also called a neural network) is composed of collections of neurons (very simple computational units) connected together by weights (mathematical representations of how much information to allow to flow from one neuron to the next). The process of training involves finding values for each weight.


FFNN: The most straightforward way of structuring a neural network, the Feed Forward Neural Network (FFNN) structures neurons in a series of layers, with each neuron in a layer containing weights to all neurons in the previous layer.

CNN: Convolutional Neural Networks (CNN) represent nested filters over grid-organized data. They are by far the most commonly used type of model when processing images.

RNN/LSTM: Recurrent Neural Networks (RNN) and the related Long Short-Term Memory (LSTM) model types are structured to effectively represent for loops in traditional computing, collecting state while iterating over some object. They can be used for processing sequences of data.

Transformer: A more modern replacement for RNN/LSTMs, the transformer architecture enables training over larger datasets involving sequences of data.




Hyperparameters are settings on the model which are not changed during training but can affect how quickly or how reliably the model trains, such as the number of clusters the model should identify.

A loss function is used to codify the model’s distance from this goal

Training dataset: The data on which the model will be trained. Most of your data will be here.

Test dataset: The data withheld from the model during training, which is used to test how well your model will generalize to new data.

Model parameters are settings or configurations the training algorithm can update to change how the model behaves.


2.11 Quiz Model Training
---------------------------------------
True  :  The loss function measures how far the model is from its goal.

if you use all the data you have collected during training, you won't have any with which to test the model during the model evaluation phase.

hyperparameters are not updated during model training.
hyperparameters are set manually.


2.12 Model Evaluation
---------------------------------------
Model accuracy is a fairly common evaluation metric. Accuracy is the fraction of predictions a model gets right.

Using Log Loss
Log loss seeks to calculate how uncertain your model is about the predictions it is generating. In this context, uncertainty refers to how likely a model thinks the predictions being generated are to be correct.


Log loss seeks to calculate how uncertain your model is about the predictions it is generating.

Model Accuracy is the fraction of predictions a model gets right.



2.13 Quiz: Model Evaluation 
---------------------------------------
false : Correct! Model evaluation tools are often tailored to a specific use case.

R Square/Adjusted R Square.
Mean Square Error(MSE)/Root Mean Square Error(RMSE)
Mean Absolute Error(MAE)

The mean absolute error of a model with respect to a test set is the mean of the absolute values of the individual prediction errors on over all instances in the test set.



correct answers:

There are many different tools that can be used to evaluate a linear regression model. Here are a few examples:

Mean absolute error (MAE): This is measured by taking the average of the absolute difference between the actual values and the predictions. Ideally, this difference is minimal.

Root mean square error (RMSE): This is similar MAE, but takes a slightly modified approach so values with large error receive a higher penalty. RMSE takes the square root of the average squared difference between the prediction and the actual value.

Coefficient of determination or R-squared (R^2): This measures how well-observed outcomes are actually predicted by the model, based on the proportion of total variation of outcomes.


2.14 Model Inference
---------------------------------------
Once you have trained your model, have evaluated its effectiveness, and are satisfied with the results, you're ready to generate predictions on real-world problems using unseen data in the field. In machine learning, this process is often called inference.


2.15 Quiz: Model Inference
---------------------------------------
generating predictions
finding patterns in your data.
using a trained model.
testing your model on data it has not seen before


2.16 Introduction to Examples
---------------------------------------
Supervised learning
Using machine learning to predict housing prices in a neighborhood based on lot size and number of bedrooms

Unsupervised learning
Using machine learning to isolate micro-genres of books by analyzing the wording on the back cover description.

Deep neural network
While this type of task is beyond the scope of this lesson, we wanted to show you the power and versatility of modern machine learning. You will see how it can be used to analyze raw images from lab video footage from security cameras, trying to detect chemical spills.


2.17 Example One: House Price Prediction
---------------------------------------
Continuous: Floating-point values with an infinite range of possible values. The opposite of categorical or discrete values, which take on a limited number of possible values.
Hyperplane: A mathematical term for a surface that contains more than two planes.
Plane: A mathematical term for a flat surface (like a piece of paper) on which two points can be joined by a straight line.
Regression: A common task in supervised machine learning.


2.18 Quiz: Example One
---------------------------------------
false

throwing a ball for a distance.


Linear models typically fail when there is no helpful linear relationship between the input variables and the label.

For example, imagine predicting the height (label) of a thrown projectile over time (input variable). You know the trajectory is not linear; it's curved. Any straight line you try to use to describe this phenomenon would be invalid for a large range of the projectile's trajectory.

Techniques do exist to modify your data so you can still use linear models in these situations. Such methods are out of scope for this course but are called kernel methods.


2.19 Example Two: Book Genre Exploration
---------------------------------------
Bag of words: A technique used to extract features from the text. It counts how many times a word appears in a document (corpus), and then transforms that information into a dataset.
Data vectorization: A process that converts non-numeric data into a numerical format so that it can be used by a machine learning model.
Silhouette coefficient: A score from -1 to 1 describing the clusters found during modeling. A score near zero indicates overlapping clusters, and scores less than zero indicate data points assigned to incorrect clusters. A score approaching 1 indicates successful identification of discrete non-overlapping clusters.
Stop words: A list of words removed by natural language processing tools when building your dataset. There is no single universal list of stop words used by all-natural language processing tools.


2.20
---------------------------------------


2.21
---------------------------------------


2.22
---------------------------------------


2.23
---------------------------------------


2.24
---------------------------------------


2.25
---------------------------------------


2.26
---------------------------------------


2.2
---------------------------------------



